Homework 2
================
Yuki Joyama
2023-09-26

# Problem 1

Import and clean the data in pols-month.csv

``` r
pols_month_df =
  read_csv("./fivethirtyeight_datasets/pols-month.csv") |> # import pols_month.csv file
  separate(col=mon, into=c("year", "month", "day")) |> # separate mon variable into year, month and day
  mutate(
    year = as.integer(year), # change the class of year, month, day to integer
    month = as.integer(month),
    day = as.integer(day),
    month = case_match(
    month,
    01 ~ "jan",
    02 ~ "feb",
    03 ~ "mar",
    04 ~ "apr",
    05 ~ "may",
    06 ~ "jun",
    07 ~ "jul",
    08 ~ "aug",
    09 ~ "sep",
    10 ~ "oct",
    11 ~ "nov",
    12 ~ "dec"
    ), # replace month number with month name
    president = case_when(
      prez_gop == 1 ~ "gop",
      prez_dem == 1 ~ "dem"
    ) # make a new variable president with values gop and dem
  ) |> 
  select(-c("prez_dem", "prez_gop", "day")) # remove prez_dem, prez_gop, and day

pols_month_df
```

    ## # A tibble: 822 × 9
    ##     year month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##    <int> <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ##  1  1947 jan        23      51     253      23      45     198 dem      
    ##  2  1947 feb        23      51     253      23      45     198 dem      
    ##  3  1947 mar        23      51     253      23      45     198 dem      
    ##  4  1947 apr        23      51     253      23      45     198 dem      
    ##  5  1947 may        23      51     253      23      45     198 dem      
    ##  6  1947 jun        23      51     253      23      45     198 dem      
    ##  7  1947 jul        23      51     253      23      45     198 dem      
    ##  8  1947 aug        23      51     253      23      45     198 dem      
    ##  9  1947 sep        23      51     253      23      45     198 dem      
    ## 10  1947 oct        23      51     253      23      45     198 dem      
    ## # ℹ 812 more rows

Import and clean the data in snp.csv

``` r
snp_df =
  read_csv("./fivethirtyeight_datasets/snp.csv") |> # import snp.csv file
  separate(col = date, into = c("month", "day", "year")) |> # separate date variable into year, month and day
  mutate(
    year = as.integer(year), # change the class of year, month, day to integer
    month = as.integer(month),
    day = as.integer(day),
    year = case_when(
      year < 23 ~ 2000 + year,
      year >=23 ~ 1900 + year
    ) # if year < 23, add 2000; if year >= 23, add 1900
  ) |> 
  arrange(year, month) |> # arrange order according to year and month
  mutate(
    month = case_match(
    month,
    01 ~ "jan",
    02 ~ "feb",
    03 ~ "mar",
    04 ~ "apr",
    05 ~ "may",
    06 ~ "jun",
    07 ~ "jul",
    08 ~ "aug",
    09 ~ "sep",
    10 ~ "oct",
    11 ~ "nov",
    12 ~ "dec"
    ) # replace month number with month name
  ) |> 
  relocate(year, month) |> # change position of columns year and month
  select(-"day") # remove day

snp_df
```

    ## # A tibble: 787 × 3
    ##     year month close
    ##    <dbl> <chr> <dbl>
    ##  1  1950 jan    17.0
    ##  2  1950 feb    17.2
    ##  3  1950 mar    17.3
    ##  4  1950 apr    18.0
    ##  5  1950 may    18.8
    ##  6  1950 jun    17.7
    ##  7  1950 jul    17.8
    ##  8  1950 aug    18.4
    ##  9  1950 sep    19.5
    ## 10  1950 oct    19.5
    ## # ℹ 777 more rows

Import and clean the data in unemployment.csv

``` r
unemployment_df =
  read_csv("./fivethirtyeight_datasets/unemployment.csv") |> # import unemployment.csv file
  janitor::clean_names() |> # clean the variables name
  pivot_longer(
    cols = c("jan","feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"),
    names_to = "month",
    values_to = "unemployment_rate"
  ) # change the dataset from wide to long

unemployment_df
```

    ## # A tibble: 816 × 3
    ##     year month unemployment_rate
    ##    <dbl> <chr>             <dbl>
    ##  1  1948 jan                 3.4
    ##  2  1948 feb                 3.8
    ##  3  1948 mar                 4  
    ##  4  1948 apr                 3.9
    ##  5  1948 may                 3.5
    ##  6  1948 jun                 3.6
    ##  7  1948 jul                 3.6
    ##  8  1948 aug                 3.9
    ##  9  1948 sep                 3.8
    ## 10  1948 oct                 3.7
    ## # ℹ 806 more rows

Now, let’s merge snp into pols, and merge unemployment data into the
result.

``` r
fivethrityeight_df =
  left_join(pols_month_df, snp_df, by = c("year", "month")) |> # merge snp into pols,
  left_join(unemployment_df, by = c("year", "month")) |> # merge unemployment data into the result
  relocate("year", "month", "president", "close", "unemployment_rate") # bring key variables to the front

fivethrityeight_df
```

    ## # A tibble: 822 × 11
    ##     year month president close unemployment_rate gov_gop sen_gop rep_gop gov_dem
    ##    <dbl> <chr> <chr>     <dbl>             <dbl>   <dbl>   <dbl>   <dbl>   <dbl>
    ##  1  1947 jan   dem          NA                NA      23      51     253      23
    ##  2  1947 feb   dem          NA                NA      23      51     253      23
    ##  3  1947 mar   dem          NA                NA      23      51     253      23
    ##  4  1947 apr   dem          NA                NA      23      51     253      23
    ##  5  1947 may   dem          NA                NA      23      51     253      23
    ##  6  1947 jun   dem          NA                NA      23      51     253      23
    ##  7  1947 jul   dem          NA                NA      23      51     253      23
    ##  8  1947 aug   dem          NA                NA      23      51     253      23
    ##  9  1947 sep   dem          NA                NA      23      51     253      23
    ## 10  1947 oct   dem          NA                NA      23      51     253      23
    ## # ℹ 812 more rows
    ## # ℹ 2 more variables: sen_dem <dbl>, rep_dem <dbl>

After the cleaning process, pols_month_df has 9 variables including
year, month, president (whether the president was republican or
democratic), etc; snp_df has three variables including year, month, and
close (the closing values of the S&P stock index at the associated
time); unemployment_df has three variables including year, month, and
unemployment_rate (percentage of unemployment at the associated time).  
Merging these three datasets gives the resulting dataset
fivethirtyeight_df. This dataset has 11 variables (year, month,
president, close, unemployment_rate, etc and 822 rows. The year in this
dataset ranges from 1947 to 2015.

# Problem 2

``` r
# import dataset from each sheet in excel file
mister_df =
  readxl::read_excel("202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N586") |> # data of Mr. Trash Wheel
  janitor::clean_names()

professor_df =
  readxl::read_excel("202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M108") |> # data of Professor Trash Wheel
  janitor::clean_names()

gwynnda_df =
  readxl::read_excel("202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:L158") |> # data of Gwynnda Trash Wheel
  janitor::clean_names()
```

\*Homes Powered - Each ton of trash equates to on average 500 kilowatts
of electricity. An average household will use 30 kilowatts per day.

Following the above note, I will calculate homes_powered variable for
every dumpster data and update it in each dataset. I will also add an
additional variable which specifies the name of Trash Wheel.

``` r
mister_df = mister_df |> 
  mutate(
    homes_powered = (weight_tons * 500) / 30,
    name = "mister"
  ) |> 
  relocate("name") # bring the name to the front

professor_df = professor_df |> 
  mutate(
    homes_powered = (weight_tons * 500) / 30,
    name = "professor"
  ) |> 
  relocate("name") # bring the name to the front

gwynnda_df = gwynnda_df |> 
  mutate(
    homes_powered = (weight_tons * 500) / 30,
    name = "gwynnda"
  ) |> 
  relocate("name") # bring the name to the front

# show results
mister_df
```

    ## # A tibble: 584 × 15
    ##    name  dumpster month year  date                weight_tons volume_cubic_yards
    ##    <chr>    <dbl> <chr> <chr> <dttm>                    <dbl>              <dbl>
    ##  1 mist…        1 May   2014  2014-05-16 00:00:00        4.31                 18
    ##  2 mist…        2 May   2014  2014-05-16 00:00:00        2.74                 13
    ##  3 mist…        3 May   2014  2014-05-16 00:00:00        3.45                 15
    ##  4 mist…        4 May   2014  2014-05-17 00:00:00        3.1                  15
    ##  5 mist…        5 May   2014  2014-05-17 00:00:00        4.06                 18
    ##  6 mist…        6 May   2014  2014-05-20 00:00:00        2.71                 13
    ##  7 mist…        7 May   2014  2014-05-21 00:00:00        1.91                  8
    ##  8 mist…        8 May   2014  2014-05-28 00:00:00        3.7                  16
    ##  9 mist…        9 June  2014  2014-06-05 00:00:00        2.52                 14
    ## 10 mist…       10 June  2014  2014-06-11 00:00:00        3.76                 18
    ## # ℹ 574 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>

``` r
professor_df
```

    ## # A tibble: 106 × 14
    ##    name  dumpster month  year date                weight_tons volume_cubic_yards
    ##    <chr>    <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ##  1 prof…        1 Janu…  2017 2017-01-02 00:00:00        1.79                 15
    ##  2 prof…        2 Janu…  2017 2017-01-30 00:00:00        1.58                 15
    ##  3 prof…        3 Febr…  2017 2017-02-26 00:00:00        2.32                 18
    ##  4 prof…        4 Febr…  2017 2017-02-26 00:00:00        3.72                 15
    ##  5 prof…        5 Febr…  2017 2017-02-28 00:00:00        1.45                 15
    ##  6 prof…        6 March  2017 2017-03-30 00:00:00        1.71                 15
    ##  7 prof…        7 April  2017 2017-04-01 00:00:00        1.82                 15
    ##  8 prof…        8 April  2017 2017-04-20 00:00:00        2.37                 15
    ##  9 prof…        9 May    2017 2017-05-10 00:00:00        2.64                 15
    ## 10 prof…       10 May    2017 2017-05-26 00:00:00        2.78                 15
    ## # ℹ 96 more rows
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>

``` r
gwynnda_df
```

    ## # A tibble: 156 × 13
    ##    name  dumpster month  year date                weight_tons volume_cubic_yards
    ##    <chr>    <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ##  1 gwyn…        1 July   2021 2021-07-03 00:00:00        0.93                 15
    ##  2 gwyn…        2 July   2021 2021-07-07 00:00:00        2.26                 15
    ##  3 gwyn…        3 July   2021 2021-07-07 00:00:00        1.62                 15
    ##  4 gwyn…        4 July   2021 2021-07-16 00:00:00        1.76                 15
    ##  5 gwyn…        5 July   2021 2021-07-30 00:00:00        1.53                 15
    ##  6 gwyn…        6 Augu…  2021 2021-08-11 00:00:00        2.06                 15
    ##  7 gwyn…        7 Augu…  2021 2021-08-14 00:00:00        1.9                  15
    ##  8 gwyn…        8 Augu…  2021 2021-08-16 00:00:00        2.16                 15
    ##  9 gwyn…        9 Augu…  2021 2021-08-16 00:00:00        2.6                  15
    ## 10 gwyn…       10 Augu…  2021 2021-08-17 00:00:00        3.21                 15
    ## # ℹ 146 more rows
    ## # ℹ 6 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>

Now, let’s combine the three datasets.

``` r
# change year variable in mister_df from chr to int
mister_df = mister_df |> 
  mutate(year = as.integer(year))

# combine datasets
trash_wheel_df =
  bind_rows(mister_df, professor_df, gwynnda_df)

trash_wheel_df
```

    ## # A tibble: 846 × 15
    ##    name  dumpster month  year date                weight_tons volume_cubic_yards
    ##    <chr>    <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ##  1 mist…        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2 mist…        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3 mist…        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4 mist…        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5 mist…        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6 mist…        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7 mist…        7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8 mist…        8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9 mist…        9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10 mist…       10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # ℹ 836 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>

The resulting dataset trash_wheel_df has 846 observations and 15
variables such as name (the name of the trash wheel), month, year,
dumpster (the dumpster number), weight_tons (amount of total litter),
variables indicating litter type, etc.

The total weight of trash collected by Professor Trash Wheel was 216.26
tons.

``` r
# filter gwynnda data by year and month 
gwynnda_cig_july2021 = gwynnda_df |> 
  filter(year == 2021 & month == "July") 

gwynnda_cig_july2021 = sum(pull(gwynnda_cig_july2021, cigarette_butts)) # calculate cigarette butts collected by Gwynnda
```

The total number of cigarette butts collected by Gwynnda in July of 2021
was 16300.

# Problem 3

**Study baseline**

``` r
# import the csv files
mci_baseline_df =
  read_csv("./data_mci/MCI_baseline.csv", skip = 1) |> # start reading from row 2
  janitor::clean_names() |> 
  mutate(
    sex = case_match(  
      sex,
      1 ~ "male",
      0 ~ "female"
    ),  # rewrite sex variables
    apoe4 = case_match(
      apoe4,
      1 ~ "carrier",
      0 ~ "non-carrier"
    ),  # rewrite apoe4 variables
    age_at_onset = if_else(age_at_onset == ".", NA, as.numeric(age_at_onset))
  )  # replace "." with missing values and change the values in age_at_onset to numeric values

mci_free_baseline_df = mci_baseline_df |> 
  filter(age_at_onset - current_age > 0 | is.na(age_at_onset)) # exclude if MCI + at baseline

mci_new_beseline_df = mci_baseline_df |> 
  filter(age_at_onset - current_age > 0)

# calculate the proportion of women who are APOE4 carriers
women_apoe4 = nrow(filter(mci_free_baseline_df, sex == "female" & apoe4 == "carrier")) / nrow(filter(mci_free_baseline_df, sex== "female"))
```

According to the baseline dataset, 483 participants were recruited in
this study.  
4 participants were excluded because they already had the MCI at the
study baseline. Among those who are included, 93 participants developed
MCI.  
The average baseline age for the eligible study participants is 65.03
and the proportion of women who are APOE4 carriers is 0.3.

**Biomarker data**

``` r
# import the csv files
mci_amyloid_df =
  read_csv("./data_mci/mci_amyloid.csv", skip = 1) |> # start reading from row 2
  janitor::clean_names() |>
  rename(id = study_id)  # change the column name

# check ids of participants excluded from the baseline dataset
excluded_id = mci_baseline_df |> 
  filter(age_at_onset - current_age <= 0) |> 
  pull(id)

# exclude these ids from the biomarker data
mci_amyloid_df = mci_amyloid_df |> 
  filter(!id %in% c(excluded_id))
```

After excluding participants who did not meet the inclusion criteria,
the biomarker data (mci_amyloid_df) includes the amyloid beta 42/40
ratio data for 483 participants. The amyloid beta 42/40 ratio was
collected at baseline and at 2, 4, 6, and 8 years following the initial
visit (baseline).

**Compare baseline and biomarker data**

``` r
# show rows only in mci_free_baseline_df
anti_join(mci_free_baseline_df, mci_amyloid_df, by = "id")
```

    ## # A tibble: 8 × 6
    ##      id current_age sex    education apoe4       age_at_onset
    ##   <dbl>       <dbl> <chr>      <dbl> <chr>              <dbl>
    ## 1    14        58.4 female        20 non-carrier         66.2
    ## 2    49        64.7 male          16 non-carrier         68.4
    ## 3    92        68.6 female        20 non-carrier         NA  
    ## 4   179        68.1 male          16 non-carrier         NA  
    ## 5   268        61.4 female        18 carrier             67.5
    ## 6   304        63.8 female        16 non-carrier         NA  
    ## 7   389        59.3 female        16 non-carrier         NA  
    ## 8   412        67   male          16 carrier             NA

``` r
# show rows only in mci_amyloid_df
anti_join(mci_amyloid_df, mci_free_baseline_df, by = "id")
```

    ## # A tibble: 12 × 6
    ##       id baseline    time_2      time_4      time_6      time_8     
    ##    <dbl> <chr>       <chr>       <chr>       <chr>       <chr>      
    ##  1   484 0.11139422  0.110936838 0.109182887 0.110607585 0.107057538
    ##  2   485 0.106042813 0.105158363 0.107758828 0.107281321 0.106181816
    ##  3   486 0.109161071 0.114634379 <NA>        0.110035156 0.107234758
    ##  4   487 0.110821971 0.107791347 0.109855229 0.110951271 0.105861634
    ##  5   488 0.110418756 0.111994328 0.113132987 0.108902038 0.109449907
    ##  6   489 0.11477384  0.113322128 0.115109381 0.116004489 0.112260161
    ##  7   490 0.111762756 0.109627815 0.111492905 0.110104053 <NA>       
    ##  8   491 0.116934974 0.113763228 0.111358448 0.110509854 0.110541984
    ##  9   492 0.109757685 0.109912273 0.110672861 0.109064952 0.109161341
    ## 10   493 0.108357146 0.108161281 0.109491179 0.104448142 0.108636703
    ## 11   494 0.116669151 0.109711076 0.112133216 0.111399722 0.108836759
    ## 12   495 Na          0.105142354 0.108149625 0.105918659 0.102512562

The above output shows that participants with ID: 14, 49, 92, 179, 268,
304, 389, 412 are only registered in the baseline dataset, and ID: 484,
485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495 are only in the
biomarker dataset.

Next, I will combine the two datasets that share common IDs.

``` r
# combine two datasets
mci_df = inner_join(mci_free_baseline_df, mci_amyloid_df) |> 
    pivot_longer(  # change the dataset from wide to long
    baseline:time_8,
    names_to = "time",
    values_to = "amyloid_ratio"
  )

mci_df
```

    ## # A tibble: 2,355 × 8
    ##       id current_age sex    education apoe4   age_at_onset time    amyloid_ratio
    ##    <dbl>       <dbl> <chr>      <dbl> <chr>          <dbl> <chr>   <chr>        
    ##  1     1        63.1 female        16 carrier           NA baseli… 0.1105487    
    ##  2     1        63.1 female        16 carrier           NA time_2  <NA>         
    ##  3     1        63.1 female        16 carrier           NA time_4  0.109325197  
    ##  4     1        63.1 female        16 carrier           NA time_6  0.104756131  
    ##  5     1        63.1 female        16 carrier           NA time_8  0.107257697  
    ##  6     2        65.6 female        20 carrier           NA baseli… 0.107481183  
    ##  7     2        65.6 female        20 carrier           NA time_2  0.109157373  
    ##  8     2        65.6 female        20 carrier           NA time_4  0.109457839  
    ##  9     2        65.6 female        20 carrier           NA time_6  0.105729713  
    ## 10     2        65.6 female        20 carrier           NA time_8  0.10661845   
    ## # ℹ 2,345 more rows

This dataset has 2355 rows and 8 columns including id, current_age, sex,
education, apoe4, age_at_onset, time, amyloid_ratio.

Finally, I will export mci_df as a csv file.

``` r
write_csv(mci_df, "./data_mci/mci_df_cleaned.csv")
```
